---
title: "Kaggle Competition"
author: "Alon Rashty & Yuval Rittberg"
date: "6/31/2021"
output:
  html_document: 
    theme: readable
    toc: yes
    toc_depth: 2
    toc_float: yes
    code_folding: show
editor_options: 
  chunk_output_type: console
---

# Packages & Functions
```{r , class.source = 'fold-hide', message = FALSE, warning = FALSE}
if (!require("pacman")) install.packages("pacman")
  pacman::p_load(
    
    # For data manipulation, analysis and visualization
    tidyverse,
    summarytools,
    DataExplorer,
    gridExtra,
    kableExtra,
    papeR,
    sorensonimpact,
    corrplot,
    
    # For modeling
    tidymodels,
    glmnet,
    e1071,
    gbm,
    randomForest,
    xgboost,
    
    # For performance
    doParallel
    )
  
  devtools::install_github("Sorenson-Impact/sorensonimpact")


# Function to detect binary variables
is_binary <- function(x) {
  x0 <- na.omit(x)
  is.numeric(x) && length(unique(x0)) %in% 1:2 && all(x0 %in% 0:1)
}

# Function for table formatting
kable_format <- function(x, digits = 1, caption = NULL,
                         position = "center"
                         ) {
  kbl(x = x, digits = digits, caption = caption) %>% 
  row_spec(row = 0,bold = TRUE) %>% 
  kable_classic_2(lightable_options = c("bordered", "hover"), full_width = F, 
                  html_font = "Cambria",position = position
                  )
}  
```

# Data
```{r, message=FALSE}
train_raw <- read_csv("Kaggle/train.csv") # %>% 
  mutate(across(where(is_binary), ~ factor(., levels = 0:1)))

train <- train_raw # For analysis

test <- read_csv("Kaggle/test.csv") %>% 
  mutate(across(where(is_binary), ~ factor(., levels = 0:1)))

# # Split variables to discrete and continuous
# train_explore <- train %>% 
#   select(-ID) %>% 
#   split_columns()
# 
# continuous <- names(train_explore$continuous)
# discrete <- names(train_explore$discrete)
```


```{r}

corr_simple <- function(data=df,sig=0.5){
  #run a correlation and drop the insignificant ones
  corr <- cor(data)
  #prepare to drop duplicates and correlations of 1     
  corr[lower.tri(corr,diag=TRUE)] <- NA 
  #drop perfect correlations
  corr[corr == 1] <- NA 
  #turn into a 3-column table
  corr <- as.data.frame(as.table(corr))
  #remove the NA values from above 
  corr <- na.omit(corr) 
  #select significant values  
  corr <- subset(corr, abs(Freq) > sig) 
  #sort by highest correlation
  corr <- corr[order(-abs(corr$Freq)),] 
  #print table
  print(corr)
  #turn corr back into matrix in order to plot with corrplot
  mtx_corr <- reshape2::acast(corr, Var1~Var2, value.var="Freq")
  
  #plot correlations visually
  corrplot(mtx_corr, is.corr=FALSE, tl.col="black", na.label=" ")
}

corr_simple(train_rec, sig = 0.9)
```


## First look
```{r, results='asis'}
summarise(train, digits = 1, sep = TRUE, count = FALSE) %>% kable_format()
summarise(test, digits = 1, sep = TRUE, count = FALSE) %>% kable_format()


```
We can see that `farmer` is always zero, so it'll be dropped in the recipe.

There is one observation with `edyrs==0`. He is Hispanic, male, construction worker. Should we drop it?

## Correlation
```{r}
corrplot(cor(train),
+          method = "number",
+          type = "upper")
```


## Education
Let's look at the feature `edyrs`
```{r}
train %>% ggplot(aes(edyrs)) + 
  geom_histogram(binwidth = 1)
```

We can see that there's a relatively significant concentration at the value of 12 and 16, which represent finishing high school and college, respectively. We don't think there's important information between the values below 12, so we'll replace this feature with a dummy for finishing high school. 

The values of 13-15 and 17 can imply for students. We can check their experience and see if it makes sense:
```{r}
train %>% 
  filter(edyrs %in% c(13:15)) %>% 
  ggplot(aes(expf)) +
  geom_histogram(binwidth = 1)
```

We can't conclude that these are students, maybe dropouts?

# Occupation

```{r}


occupations <- c("manager", "business", "financialop", "computer", "architect", "scientist", "socialworker", "postseceduc", "legaleduc", "artist", "lawyerphysician", "healthcare", "healthsupport", "protective", "foodcare", "building", "sales", "officeadmin", "farmer", "constructextractinstall", "production", "transport")

train_cat <- train %>% select(occupations) %>% sweep(2, c(1:length(occupations)), "*") %>% mutate(occupation = rowSums(.)) %>% bind_cols(train %>% select(lnwage)) 
train_cat %>% group_by(occupation) %>% dplyr::summarise(x = mean(exp(lnwage))) %>% arrange(desc(x)) %>% kable_format()

train_cat %>% ggplot(aes(x = reorder(occupation, lnwage, FUN = median), y = lnwage, fill = as_factor(occupation))) +
  geom_boxplot()


```


## Creating features for exploration
```{r}
train <- train %>% 
  mutate(in_school = as_factor(if_else(edyrs %in% c(13:15, 17), 1, 0)),
         educ = fct_case_when(
           edyrs <= 12   ~ "high school",
           edyrs %in% c(13:16) ~ "college",
           edyrs > 16  ~ "advanced"),
         region = case_when(
           northeast==1    ~ "northeast",
           northcentral==1 ~ "northcentral",
           south==1        ~ "south", 
           TRUE            ~ "other"),
         race = case_when(
           black==1     ~ "black", 
           hisp==1      ~ "hisp", 
           otherrace==1 ~ "otherrace", 
           TRUE         ~ "white")
         )


train <- train_raw %>% mutate(high_school = if_else(edyrs<=12, 1, 0),
                              white = if_else(black==0 & hisp==0 & otherrace==0, 1, 0),
                              academic = if_else(edyrs>=16, 1, 0),
                              white_collar = if_else(manager==1 | business==1 | financialop==1 | computer==1 | scientist==1 | legaleduc==1 | lawyerphysician==1 | healthcare==1, 1, 0)
)
```

```{r}
train %>% 
  ggplot(aes(x = region, y = lnwage, fill = female)) +
  geom_boxplot() 

train %>% 
  ggplot(aes(x = race, y = lnwage, fill = female)) +
  geom_boxplot() 

train %>% 
  ggplot(aes(x = educ, y = lnwage, fill = female)) +
  geom_boxplot() 

train %>% 
  filter(edyrs<=12) %>% 
  ggplot(aes(x = edyrs, y = lnwage))+
  geom_jitter() + 
  geom_smooth()
```
The south might be poorer then the rest.



```{r}
ggplot(train, aes(x = race, y = lnwage, fill = female)) +
  geom_boxplot() 

tree_fit <- rpart(formula = lnwage ~ .,
                  data = train,
                  method = "anova",
                  control = rpart.control(minsplit = 2, minbucket = 1)
)

rpart.plot(tree_fit, roundint = FALSE)


# Other
plot_histogram(train)
##plot_correlation(train_explore)

```

# Modelling
```{r}
# Cross validation folds
cv_folds <- train %>% 
  vfold_cv(v = 5) # can also add repeats and strata

# Base recipe (data processing)
train_rec <- recipe(lnwage ~ ., data = train) %>% 
  update_role(ID, new_role = "ID") %>% 
  step_rm(edyrs) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_interact(~ all_predictors():all_predictors()) %>% 
  step_corr(all_predictors(), threshold = 1) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())

```

## LASSO
```{r}
# Model definition
lasso_model <- 
  linear_reg(penalty = tune(), mixture = 1) %>% 
    set_engine("glmnet") %>% 
    set_mode("regression")

# Define parameters for tuning
lasso_grid <- grid_regular(penalty(), levels = 50)

# Combine models and workflow
lasso_wf <- workflow() %>% 
  add_recipe(train_rec) %>% 
  add_model(lasso_model)

# Tune parameters
lasso_results <- lasso_wf %>% 
  tune_grid(grid = lasso_grid,
            resamples = cv_folds)

lasso_results %>% show_best(metric = "rmse")

# Visualize results (try to plot both models)
lasso_results %>% 
  collect_metrics() %>%
  filter(.metric == "rmse") %>% 
    ggplot(aes(penalty, mean)) +
      geom_errorbar(aes(
        ymin = mean - std_err,
        ymax = mean + std_err)
        ) +
      geom_line(size = 1.5) +
      scale_x_log10() +
      theme(legend.position = "none")

# Select best model
lasso_best <- lasso_results %>% 
select_best(metric = "rmse")

lambda_1se <- lasso_results %>% 
  select_by_one_std_err(
    metric = "rmse",
    desc(penalty)
  ) %>% 
  select(penalty)

# Finalize workflow
lasso_final <- finalize_workflow(lasso_wf, lasso_best)
lasso_model_final <- finalize_model(lasso_model, lasso_best)
lasso_final_fit <- fit(lasso_model_final, lnwage ~ ., data = train)

# Variable importance
lasso_final %>% fit(data = train) %>% pull_workflow_fit() %>% vip(geom = "point")

```

## Random Forests
```{r}
# Define model
rf_model <- 
  rand_forest(mtry = tune(), 
              trees = tune(),
              min_n = tune()
              ) %>% 
  set_engine("randomForest") %>% 
  set_mode("regression")

# Define parameters for tuning
rf_grid <- grid_latin_hypercube(
  mtry(c(6,10)), 
  trees(),
  min_n(),
  size = 30
  )

# Combine model and recipe
rf_wf <- 
  workflow() %>% 
  add_recipe(train_rec) %>% 
  add_model(rf_model)

# Tune parameters
rf_results <- 
  tune_grid(rf_wf,
            resamples = cv_folds,
            grid = rf_grid,
            control = control_grid(save_pred = TRUE)
            )

# Evaluate tuning results
show_best(rf_results, "rmse", n = 10)

# Visualize results
rf_results %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  select(mean, mtry:min_n) %>%
  pivot_longer(mtry:min_n,
               values_to = "value",
               names_to = "parameter"
               ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "rmse")

# Select best model
rf_best <- select_best(rf_results, metric = "rmse")
# Or select by one std err (the additional arguments arrange the results by these parameters - do we want that?)
# rf_1std <- select_by_one_std_err(rf_results, mtry, trees, min_n, metric = "rmse")

# Finalize workflow
rf_final <- finalize_workflow(rf_wf, rf_best)
rf_model_final <- finalize_model(rf_model, rf_best)
rf_final_fit <- fit(rf_model_final, lnwage ~ ., data = train)

# Variable importance
rf_final %>% fit(data = train) %>% pull_workflow_fit() %>% vip(geom = "point")
  
  
```

## XGBoost
```{r}
# XGBoost (can tune more parameters)
  # Define model
  xgb_model <- 
    boost_tree(mtry = tune(),             # number of predictors to choose from at each split (for randomness)
                 trees = tune(),          # number of trees (complexity)
                 min_n = tune(),          # minimum obs in a node (complexity)
                 tree_depth = tune(),     # max number of split (complexity)
                 learn_rate = tune(),     # step size
                 loss_reduction = tune(), # the reduction in the loss function required to split further
                 sample_size = tune()     # fraction of data in each round (for randomness)
                 ) %>%
    set_mode("regression") %>% 
    set_engine("xgboost", objective = "reg:squarederror")
    
# Define parameters for tuning
 xgb_grid <- grid_latin_hypercube(
   trees(),
   tree_depth(),
   min_n(),
   loss_reduction(),
   sample_size = sample_prop(),
   finalize(mtry(), train),
   learn_rate(),
   size = 30
   )

# Combine model and recipe
xgb_wf <- 
  workflow() %>% 
  add_recipe(train_rec) %>% 
  add_model(xgb_model)

# Tune parameters
xgb_results <- 
  tune_grid(xgb_wf,
            resamples = cv_folds,
            grid = xgb_grid,
            control = control_grid(save_pred = TRUE)
            )

# Evaluate tuning results
show_best(xgb_results, "rmse", n = 10)

# Visualize results
xgb_results %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  select(mean, mtry:sample_size) %>%
  pivot_longer(mtry:sample_size,
               values_to = "value",
               names_to = "parameter"
               ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "rmse")

# Select best model
xgb_best <- select_best(xgb_results, metric = "rmse")
# Or select by one std err (the additional arguments arrange the results by these parameters - do we want that?)
# xgb_1std <- select_by_one_std_err(xgb_results, mtry, tree_depth, trees, min_n, 
#                       metric = "rmse")

# Finalize workflow
xgb_final <- finalize_workflow(xgb_wf, xgb_best)
xgb_model_final <- finalize_model(xgb_model, xgb_best)
xgb_final_fit <- fit(xgb_model_final, lnwage ~ ., data = train)

# Variable importance
xgb_final %>% fit(data = train) %>% pull_workflow_fit() %>% vip(geom = "point")
  

```

## Prediction
```{r}
# Predict on test data
xgb_pred <- 
    predict(xgb_final_fit, new_data = test) %>% 
    bind_cols(select(test, ID))
```




# Submission
```{r}
write_csv(final_prediction, "submission.csv")

```





# caret workflow
```{r}
registerDoParallel(4)

set.seed(1)

# Cross-validation and performance
control <- trainControl(method = "cv",
                        number = 5, 
                        savePredictions = "final",
                        allowParallel = TRUE)

methods <- c("lm", "rf", "gbm", "xgbTree", "xgbLinear")

model_list <- caretList(lnwage ~ ., data = train,
                        trControl = control,
                        methodList = methods,
                        tuneList = NULL,
                        continue_on_fail = FALSE, 
                        preProcess = c("center","scale"))

for (i in model_list) {
  print(i)
}

model_results <- data.frame(
 lm = min(model_list$lm$results$RMSE),
 rf = min(model_list$rf$results$RMSE),
 gbm = min(model_list$gbm$results$RMSE),
 xgbTree = min(model_list$xgbTree$results$RMSE),
 xgbLinear = min(model_list$xgbLinear$results$RMSE)
 )
print(model_results)

resamples <- resamples(model_list)
dotplot(resamples, metric = "RMSE")

modelCor(resamples)

ensemble_1 <- caretEnsemble(model_list, 
                            metric = "RMSE", 
                            trControl = control)
summary(ensemble_1)
plot(ensemble_1)

for (i in model_list) {
  pred <- predict.train(i, newdata = test) %>% 
    as_tibble() %>% 
    bind_cols(test) %>% 
    select(value, ID) %>% 
    rename(pred = value)
  
  assign(paste0(i,"_pred"), pred)
}
rm(pred)

predict_ens1 <- predict(ensemble_1, newdata = test) %>% 
    as_tibble() %>% 
    bind_cols(test) %>% 
    select(value, ID) %>% 
    rename(pred = value)


```

